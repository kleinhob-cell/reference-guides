# ğŸ§  Copilot+ AI Workflow Map  
**Model Routing â€¢ Prompt Roles â€¢ Assistant Integration**

---

## ğŸ“‘ Table of Contents
- [ğŸ§  Copilot+ AI Workflow Map](#-copilot-ai-workflow-map)
  - [ğŸ“‘ Table of Contents](#-table-of-contents)
  - [ğŸ“„ Overview](#-overview)
  - [ğŸ”€ Model Routing Summary](#-model-routing-summary)
  - [ğŸ§© Prompt â†’ Model Mapping](#-prompt--model-mapping)
  - [ğŸ“Š Installed Model Comparison](#-installed-model-comparison)
  - [ğŸ¤– Assistant Stack](#-assistant-stack)
  - [ğŸ›  Spec Prep â€” Preparing a Highâ€‘Quality Feature Specification](#-spec-prep--preparing-a-highquality-feature-specification)
    - [Available Prompts](#available-prompts)
    - [Workflow](#workflow)
    - [Why This Matters](#why-this-matters)
  - [ğŸ“‹ Feature Specification Guide](#-feature-specification-guide)
    - [âš™ï¸ Full Feature Pipeline Usage](#ï¸-full-feature-pipeline-usage)
    - [Purpose](#purpose)
    - [When to Use](#when-to-use)
    - [How to Run in Continue](#how-to-run-in-continue)
    - [Example Input](#example-input)
    - [Example Output Structure](#example-output-structure)
    - [How to Run in Continue](#how-to-run-in-continue-1)
    - [Example Input](#example-input-1)
  - [âš ï¸ Removed Models (Audit Notes)](#ï¸-removed-models-audit-notes)

---

## ğŸ“„ Overview
This workflow map documents how prompts, models, and assistant roles are routed in the current Ollamaâ€‘based Copilot+ stack.

It is designed to:
- **Ensure reproducibility** â€” every model and prompt pairing is intentional, documented, and can be reâ€‘run by future maintainers.
- **Support meetingâ€‘assistant integration** â€” enabling a smooth flow from discussion â†’ specification â†’ implementation â†’ validation.
- **Provide clear routing** â€” so anyone can see which model is best suited for a given task without guesswork.
- **Align with hardware constraints** â€” optimized for the RXâ€¯7900â€¯XTX (24â€¯GB VRAM) and reproducible Linux environments.

The map covers:
- **Model Routing Summary** â€” which model is default for each role.
- **Prompt â†’ Model Mapping** â€” explicit assignments for all prompts, including the specâ€‘toâ€‘code pipeline.
- **Installed Model Comparison** â€” VRAM, context length, strengths, weaknesses, and bestâ€‘fit scenarios.
- **Assistant Stack** â€” conversational and automation roles for dayâ€‘toâ€‘day and deepâ€‘dive tasks.
- **Spec Prep** â€” how to prepare a highâ€‘quality feature specification before coding, with promptâ€‘driven workflows.
- **Feature Specification Guide** â€” the agreed structure for specs to ensure clarity and completeness.
- **Full Feature Pipeline Usage** â€” how to go from spec to productionâ€‘ready code, tests, and optimizations in one run.

---

## ğŸ”€ Model Routing Summary

| Task Type            | Default Model               | Notes |
|----------------------|------------------------------|-------|
| **Autocomplete**     | `starcoder2_3b`              | Codeâ€‘tuned completions with good context awareness; VRAMâ€‘friendly for alwaysâ€‘on use. |
| **Rerank**           | `qwen2.5coder1b`             | Ultraâ€‘fast candidate ranking; minimal VRAM footprint; ideal for inline suggestion filtering. |
| **Chat / Build / Review** | `codellama13b`           | Balanced reasoning and generation; strong for multiâ€‘file builds and code reviews. |
| **Edit / Apply**     | `deepseekcoder6.7b`          | Fast inline edits, targeted fixes, and performance optimizations. |
| **Refactor / Explain** | `gemma3_12b`               | Longâ€‘context restructuring and clear, detailed explanations; excellent for onboarding docs. |
| **Summarize / Wrapâ€‘up** | `noushermes7b`            | Humanâ€‘like meeting summaries; quick turnaround for wrapâ€‘up notes. |
| **Automate / Spec**  | `qwen3_14b`                  | Structured, multilingual output; excels at generating specs, configs, and automation scripts. |
| **Assistant (default)** | `llama3`                  | Fast, responsive general assistant for dayâ€‘toâ€‘day queries. |
| **Assistant (deep)** | `noushermes13b`              | Richer synthesis and reasoning for complex assistant tasks. |
| **Strategic Synthesis** | `llama3_70b`              | Finalâ€‘pass analysis and nuanced reasoning for highâ€‘stakes decisions. |
| **Architect Review** | `mixtral8x7b`                | Longâ€‘context, multiâ€‘file architectural analysis and design review. |

---

## ğŸ§© Prompt â†’ Model Mapping

| Prompt Name                  | Assigned Model         | Best For |
|------------------------------|------------------------|----------|
| `build-feature`              | `codellama13b`         | Multiâ€‘step feature builds from finalized specifications. |
| `build-and-validate`         | `codellama13b`         | Generate code, selfâ€‘review for correctness, and fix issues before output. |
| `refactor-for-clarity`       | `gemma3_12b`           | Largeâ€‘context structural cleanâ€‘ups and code readability improvements. |
| `add-tests`                  | `deepseekcoder6.7b`    | Generating comprehensive, relevant pytestâ€‘style test suites. |
| `security-review`            | `codellama13b`         | Identifying subtle security issues and suggesting mitigations. |
| `optimize-performance`       | `deepseekcoder6.7b`    | Performance tuning without altering functionality. |
| `explain-code`               | `gemma3_12b`           | Detailed, clear explanations of code for onboarding or documentation. |
| `translate-language`         | `codellama13b`         | Syntaxâ€‘ and idiomâ€‘aware code translations between languages. |
| `generate-documentation`     | `codellama13b`         | Structured, readable technical documentation. |
| `debug-code`                 | `deepseekcoder6.7b`    | Pinpointing and fixing bugs in targeted code segments. |
| `code-review`                | `codellama13b`         | Style, quality, and maintainability reviews. |
| `integrate-library`          | `codellama13b`         | Multiâ€‘file library/framework integration with minimal disruption. |
| **`full-feature-pipeline`**  | `codellama13b`         | **Spec â†’ Code â†’ Validate â†’ Test â†’ Optimize** in one run. |
| **`draft-feature-spec`**     | `llama3`               | Interactive Q&A to build a complete, highâ€‘quality feature specification from scratch. |
| **`refine-feature-spec`**    | `llama3`               | Review and improve an existing feature specification for clarity, completeness, and testability. |
| **`feature-specification-guide`** | `llama3`          | Output the agreedâ€‘upon checklist for writing highâ€‘quality feature specifications. |

---

## ğŸ“Š Installed Model Comparison

| Model Name / Tag           | Size  | VRAM Use* | Context | VRAM Fit** | Strengths | Weaknesses | Best Use Cases |
|----------------------------|-------|-----------|---------|------------|-----------|------------|----------------|
| `qwen2.5coder1b`           | 1.5B  | ~2â€¯GB     | ~4K     | âœ… Dual    | Ultraâ€‘fast rerank; minimal footprint; ideal for inline suggestion filtering | Limited reasoning depth; short context | Autocomplete rerank; background candidate scoring |
| `starcoder2_3b`            | 3B    | ~4â€¯GB     | ~8K     | âœ… Dual    | Codeâ€‘tuned completions; good context awareness; VRAMâ€‘friendly | Less deep reasoning; not for largeâ€‘scale builds | Default autocomplete in editors |
| `deepseekcoder6.7b`        | 6.7B  | ~7â€¯GB     | ~4K     | âœ… Dual    | Fast inline edits; targeted fixes; performance optimization; test generation | Shorter context; less natural language fluency | Addâ€‘tests; optimizeâ€‘performance; debug small modules |
| `codellama13b`             | 13B   | ~14â€¯GB    | ~4K     | âš  Single  | Balanced reasoning and generation; strong for multiâ€‘file builds and reviews | Slower than smaller models; higher VRAM | Buildâ€‘feature; buildâ€‘andâ€‘validate; codeâ€‘review |
| `gemma3_12b`               | 12B   | ~12â€¯GB    | ~128K   | âš  Single  | Longâ€‘context restructuring; clear explanations; great for onboarding docs | Slightly slower than midâ€‘tier models | Refactorâ€‘forâ€‘clarity; explainâ€‘code |
| `qwen3_14b`                | 14B   | ~14â€¯GB    | ~32K    | âš  Single  | Structured, multilingual output; excels at specs/configs/scripts | Higher VRAM; slower load | Automate/spec creation; structured data output |
| `noushermes7b`             | 7B    | ~7â€¯GB     | ~8K     | âœ… Dual    | Humanâ€‘like summaries; quick wrapâ€‘ups | Less depth than larger assistants | Summarize meetings; wrapâ€‘up notes |
| `noushermes13b`            | 13B   | ~13â€¯GB    | ~8K     | âš  Single  | Richer synthesis; deeper reasoning than 7B | Slower; higher VRAM | Deep assistant tasks; synthesis of multiâ€‘source info |
| `llama3`                   | 8â€“10B | ~10â€¯GB    | ~8K     | âœ… Dual    | Balanced reasoning and speed; versatile | Not as deep as `llama3_70b` | Default assistant; draftâ€‘featureâ€‘spec; refineâ€‘featureâ€‘spec |
| `llama3_70b`               | 70B   | ~70â€¯GB    | ~8K     | âŒ Single  | Deep analysis; nuanced synthesis; ideal for finalâ€‘pass reviews | Heavy VRAM; slow load | Strategic synthesis; highâ€‘stakes reviews |
| `mixtral8x7b`               | MoE   | ~16â€¯GB    | ~32K    | âš  Single  | Longâ€‘context multiâ€‘file analysis; highâ€‘quality generation | Larger disk size; higher load time | Architect review; large PR/codebase analysis |

\* VRAM usage is approximate.  
\** VRAM Fit assumes RXâ€¯7900â€¯XTX (24â€¯GB VRAM).

---

## ğŸ¤– Assistant Stack

| Role                | Model             | Notes |
|---------------------|-------------------|-------|
| **Default Assistant**   | `llama3`          | Fast, balanced reasoning; ideal for dayâ€‘toâ€‘day queries, drafting, and lightweight problemâ€‘solving. |
| **Summarizer**          | `noushermes7b`    | Humanâ€‘like tone for meeting wrapâ€‘ups, quick summaries, and concise status updates. |
| **Automation / Spec**   | `qwen3_14b`       | Structured, multilingual output; excels at generating feature specs, configs, and automation scripts. |
| **Deep Assistant**      | `noushermes13b`   | Richer synthesis and reasoning for complex assistant tasks, multiâ€‘source integration, and nuanced responses. |
| **Strategic Synthesis** | `llama3_70b`      | Finalâ€‘pass analysis, deep reasoning, and highâ€‘stakes decision support. |
| **Architect Review**    | `mixtral8x7b`     | Longâ€‘context, multiâ€‘file architectural analysis; ideal for large PR/codebase reviews and design validation. |

---

## ğŸ›  Spec Prep â€” Preparing a Highâ€‘Quality Feature Specification

Before running `full-feature-pipeline`, ensure your feature specification is **complete, unambiguous, and implementationâ€‘ready**.  
This stage is critical for reproducibility, maintainability, and smooth handâ€‘offs to future maintainers.

---

### Available Prompts

- **`draft-feature-spec`** â†’ Interactive Q&A to build a new spec from scratch.  
  *Model:* `llama3`  
  *Best for:* Capturing requirements during or immediately after a meeting, using structured questioning to avoid gaps.

- **`refine-feature-spec`** â†’ Review and improve an existing spec for clarity, completeness, and testability.  
  *Model:* `llama3`  
  *Best for:* Tightening specs from stakeholders or legacy docs before implementation.

- **`feature-specification-guide`** â†’ Outputs the agreedâ€‘upon checklist for writing highâ€‘quality specs.  
  *Model:* `llama3`  
  *Best for:* Onboarding new contributors or validating that a spec meets project standards.

---

### Workflow

1. **If starting from scratch**  
   - Run `draft-feature-spec` and answer each question in detail.  
   - Use meeting assistant transcripts or notes as input to speed up Q&A.

2. **If you have a draft**  
   - Run `refine-feature-spec` to fill gaps, remove ambiguity, and improve testability.  
   - Address all suggested changes before marking the spec as final.

3. **Need a reminder of the structure?**  
   - Run `feature-specification-guide` to get the full checklist.  
   - Compare your spec against it to ensure nothing is missing.

4. **Lock the spec**  
   - Save the final version in `/docs/specs/` with a date/version tag.  
   - Commit alongside any related meeting notes for traceability.

---

### Why This Matters

- **Reproducibility** â€” A complete, structured spec ensures the same feature can be implemented consistently by different maintainers.
- **Meeting Efficiency** â€” Structured Q&A keeps requirementâ€‘gathering focused and avoids scope creep.
- **Implementation Quality** â€” Clear specs reduce rework, speed up coding, and improve test coverage.
- **Onboarding** â€” New contributors can quickly understand the featureâ€™s purpose, scope, and constraints without digging through meeting logs.

---

## ğŸ“‹ Feature Specification Guide

Use this structure to ensure every feature specification is clear, complete, and implementationâ€‘ready.  
This is the same checklist used by `feature-specification-guide` and referenced by `draft-feature-spec` and `refine-feature-spec`.

1. **Feature Overview**  
   - Purpose: Why this feature exists and the problem it solves.  
   - User Story: Who benefits and how.  
   - Scope: Boundaries of whatâ€™s included and excluded.

2. **Functional Requirements**  
   - Inputs: Data, parameters, or triggers.  
   - Outputs: Expected results or artifacts.  
   - Core Logic: Main processing steps.  
   - Edge Cases: Unusual or failure scenarios to handle.

3. **Technical Context**  
   - Language & Framework: Primary tech stack.  
   - Dependencies: Libraries, APIs, or services.  
   - Environment: OS, hardware, or runtime constraints.  
   - Performance Targets: Throughput, latency, or resource usage goals.

4. **Data & Storage**  
   - Schema: Data structures and relationships.  
   - Persistence: Where and how data is stored.  
   - Validation: Rules for data integrity.

5. **Security & Compliance**  
   - Security Measures: Authentication, encryption, access control.  
   - Compliance: Regulatory or policy requirements.

6. **Testing Expectations**  
   - Test Types: Unit, integration, endâ€‘toâ€‘end.  
   - Coverage Goals: Minimum acceptable coverage.  
   - Special Cases: Mocking, fuzzing, or load testing.

7. **Documentation Needs**  
   - Inline Comments: For maintainers.  
   - External Docs: User guides, API references.  
   - Changelog: Notable updates for release notes.

---

**Tip:**  
Before implementation, run your spec through `refine-feature-spec` to catch missing details and ambiguities.  
If youâ€™re starting from scratch, use `draft-feature-spec` to build it interactively, then validate against this guide.

---

### âš™ï¸ Full Feature Pipeline Usage

### Purpose
The `full-feature-pipeline` prompt is designed to take a **finalized, implementationâ€‘ready feature specification** and produce:
1. Productionâ€‘ready code.
2. Selfâ€‘reviewed corrections for correctness, syntax, edge cases, and security.
3. Comprehensive pytestâ€‘style unit tests.
4. Performance optimizations without changing functionality.

This ensures that a single run moves a feature from **spec â†’ validated code â†’ tests â†’ optimized implementation**.

---

### When to Use
- The feature specification has been **approved** and locked (see [Spec Prep](#-spec-prep--preparing-a-high-quality-feature-specification)).
- All functional, technical, and compliance requirements are documented.
- You want a **single, reproducible run** that outputs code, tests, and optimizations in a consistent format.
- Ideal for **handoffs** â€” future maintainers can reâ€‘run the same prompt with the same spec to reproduce the output.

---

### How to Run in Continue
1. Select the `full-feature-pipeline` prompt.
2. Paste the **finalized feature specification** into the input field.
3. Optionally include:
   - Relevant codebase context (e.g., existing modules, APIs).
   - Any architectural constraints discussed in meetings.
4. Run the prompt â€” the model will:
   - Generate the initial implementation.
   - Selfâ€‘review and correct issues.
   - Produce pytestâ€‘style tests.
   - Apply performance optimizations.
5. Review the output before committing:
   - Validate correctness in your local environment.
   - Run the generated tests in CI.
   - Document any deviations from the spec.

---

### Example Input
```markdown
## Feature Overview
Purpose: Allow meeting assistant to export summaries directly to Confluence.
User Story: As a project manager, I want meeting summaries automatically published to our Confluence space so the team can access them without manual copy-paste.
Scope: Export only finalized summaries; no draft publishing.

## Functional Requirements
Inputs: Finalized meeting summary text, Confluence API credentials.
Outputs: New Confluence page in the specified space with the summary content.
Core Logic: Authenticate with Confluence API, create page with correct title and body, confirm success.
Edge Cases: API rate limits, invalid credentials, network failures.

## Technical Context
Language: Python 3.11
Framework: None (standard library + requests)
Dependencies: requests, python-dotenv
Environment: Linux server with outbound HTTPS access
Performance Targets: Publish within 5 seconds of request.

## Data & Storage
Schema: N/A (data is transient)
Persistence: None
Validation: Ensure summary text is non-empty before publishing.

## Security & Compliance
Security Measures: Store API credentials in environment variables; never log secrets.
Compliance: Must meet internal data handling policy.

## Testing Expectations
Test Types: Unit tests for API call wrapper, integration test with mock Confluence API.
Coverage Goals: â‰¥90% for new code.
Special Cases: Simulate API failure responses.

## Documentation Needs
Inline Comments: For all functions.
External Docs: README update with usage instructions.
Changelog: Add entry for new export feature.
```

---

### Example Output Structure
```python
# Final Optimized Code
# src/confluence_exporter.py
import os
import requests
from dotenv import load_dotenv

load_dotenv()

# ... implementation code with error handling, logging, and performance optimizations ...

# Unit Tests
# tests/test_confluence_exporter.py
import pytest
from unittest.mock import patch

# ... pytest-style tests covering success, failure, and edge cases ...

# Summary of Changes and Optimizations
- Added retry logic for transient network errors.
- Reduced API call latency by reusing HTTP session.
- Improved error messages for easier debugging.
- Ensured credentials are only loaded once at startup.
```

---

**Tip:**  
For maximum reproducibility, commit:
- The **exact prompt text** used.
- The **spec** provided as input.
- The **generated output** (code + tests + summary).

This allows future maintainers to reâ€‘run the pipeline and verify results.


---

### How to Run in Continue
1. Select the `full-feature-pipeline` prompt.
2. Paste the **finalized feature specification** into the input field.
3. Optionally include:
   - Relevant codebase context (e.g., existing modules, APIs).
   - Any architectural constraints discussed in meetings.
4. Run the prompt â€” the model will:
   - Generate the initial implementation.
   - Selfâ€‘review and correct issues.
   - Produce pytestâ€‘style tests.
   - Apply performance optimizations.
5. Review the output before committing:
   - Validate correctness in your local environment.
   - Run the generated tests in CI.
   - Document any deviations from the spec.

---

### Example Input

---

## âš ï¸ Removed Models (Audit Notes)

The following models were removed during the latest stack audit to reduce redundancy, free VRAM/disk space, and improve routing clarity.  
Each removal was benchmarkâ€‘driven and documented so future maintainers can reinstate a model if a workflow gap emerges.

| Model Name / Tag       | Reason for Removal | Replacement / Reroute |
|------------------------|--------------------|-----------------------|
| `codellama7b`          | Redundant with `codellama13b` for build tasks; lower reasoning depth | `codellama13b` |
| `wizardcoder13b`       | Redundant with `codellama13b` in build/validate role | `codellama13b` |
| `phi3`                 | Lower accuracy in structured output tasks compared to `qwen3_14b` | `qwen3_14b` |

**Audit Notes:**
- All removals were validated against benchmark tasks for speed, accuracy, and fit to role.
- Disk space savings: ~38â€¯GB.
- VRAM routing is now cleaner â€” no overlapping models competing for the same role.
- If reinstating a model, update both:
  1. **Prompt â†’ Model Mapping** table.
  2. **Installed Model Comparison** section.
